---
title: 面试记录
sidebar: true
---

# 实习面试记录

<ClientOnly>
<title-pv/>
</ClientOnly>

## 百川智能LLM应用

### 9.14 一面

* 自我介绍：为什么对LLM感兴趣，对LLM有多少了解？
* 项目经历：论文核心创新点，为什么LLM在这个场景下相较于Bert有优势
* Encoder-decoder、Encode-only和Decoder-only架构的区别与优势
* RAG的技术手段
* 如何对RAG检索到的文档选优？
* 模型无法有效利用RAG检索到的文件该怎么办？
* 代码手撕：多头注意力
* GCN、GAT的基本思想？
* GAT和自注意力机制的联系？

## 美团基座LLM

### 9.19 一面

* 自我介绍
* 项目经历
    * 论文核心创新点
    * 用了多少数据进行训练？
    * 这些数据是怎么获取的？
    * 用的什么模型？多大的模型？为什么用这个模型？
    * 为什么不选用QWen、BaiChuan、GLM-4等大模型？
    * 抽取出的特征是手动预设的还是自动抽取的？
    * 在同一场景下需不需要进行特征对齐，也就是规定哪个位置必须是什么属性？比如第一个位置必须是名字，第二个位置必须是年龄？
    * 你的项目有没有微调大模型？为什么要微调？
    * SFT前后，特征能正确对齐吗？
    * 对于亚马逊的爬虫网页信息来说，有哪些内容是可以用来哺育大模型的？
    * 如果有1T级别的数据，怎么选取出1M级别适合大模型训练的数据？
* 目前有接触到哪些RAG的科研？
* 这些科研落地了吗？
* 了解o1吗？o1-mini和o1相较于GPT-4做了哪些改进？
* 你对o1的逻辑计算能力是怎么看待的？
* 多智能体协调会遇到什么问题？
* 智能体是怎么样调用工具的？
* LlaMA-2和LlaMA-3的差异？（训练数据差异，模型结构差异，适合任务差异）
* Mistral-7B和LlaMA-3-8B的差异？（训练数据差异，模型结构差异，适合任务差异）
* 有没有看过开源大模型的技术报告？
* 代码手撕：K-means
* 反问环节：
    * 目前贵司在做的是什么大模型？准备用在什么业务上？
    * 您对工业界大模型方向是怎么看的？
        <!-- * 这两年热度过大，以后会逐渐回归正常热度，看openai能不能探索出新的商业模式，从业者需要不断学习、精进自己的技能 -->
    * 您觉得我有哪些地方需要加强学习？
        * 加强对前沿知识、模型的深入理解、多一些实操经验，尤其是研究方向有差异的人如果想从事大模型行业，就需要付出更多的努力。

### 9.23 二面

* 自我介绍
* 项目经历
    * LBoost
        * 论文核心创新点
        * 用的什么大模型？
        * 改结构了吗？还是单纯应用？
        * 你觉得大模型的表现另你满意吗？
        * 不满意的原因是什么？你有什么解决办法？
        * 你所说的非结构化信息指的是什么？
        * 你的输入输出是什么？
        * 训练数据用了多少条？
        * 20到50条为什么够了？
        * LoRA的原理？
        * LoRA的权重大概长什么样，大小多大？
        * P-Tuning和Adpater-Tuning的原理？
    * MoE
        * 下游任务是什么？
        * 数据集长什么样？
        * Router是怎么训练的？
        * 为什么要用信息瓶颈？必要性？
        * 互信息是怎么算的？
        * 你还了解哪些RAG评估方式？
        * 专家的能力不同，是你们的假设，还是你们的目的？
        * 你的模型和Mistral-7*8B有什么区别？
        * 你了解正常MoE是怎么训练的吗？
* 代码手撕：无重复递增列表
* 反问环节     
    * 目前贵司在做的是什么大模型？准备用在什么业务上？
    * GPT-4o可以直接用谷歌上的优质、更新及时的内容做RAG，但国内的平台都越来越封闭反爬，目前可检索到的文章质量可以用Trash来形容，您觉得这个问题怎么解决？
    * 您觉得我有哪些地方需要加强学习？

## 百度LLM应用
### 9.20 一面

* 自我介绍
* 项目经历
    * LBoost
        * 用的什么大模型？
        * 改结构了吗？还是单纯应用？
        * 你觉得大模型的表现另你满意吗？
        * 训练数据用了多少条？
        * 你所说的非结构化信息指的是什么？
        * 这样做的必要性？
    * MoE
        * 下游任务是什么？
        * 数据集长什么样？
        * 数据增强阶段做了什么？
        * 你所说的RAG在这个任务中做了什么？
        * RAG的数据是怎么选取的？量有多大？
        * 粗排阶段是在干什么？精排阶段是在干什么？
        * 排序之后要用LLM做什么？
        * 你在这篇文章中负责的是哪部分工作？
        * 什么叫单机多租户？
        * 权重网络是怎么训练的？
        * 信息瓶颈的必要性？
* LayerNorm、BatchNorm的区别？
* 这两个Norm方式各适合什么场景？
* RAG和微调的区别？
* 什么场景适合RAG？什么场景适合微调？
* 讲一下自注意力机制
* 自注意力机制为什么要除以根号d？
* GCN为什么要左右乘以度矩阵的负二分之一次方？
* 了解哪些位置编码方式？
* 讲一下RoPE的核心思想
* 怎么样优化Prompt？有哪些提问技巧？
* 代码手撕：最长重复子串
* 反问环节：
    * 目前贵司在做的是什么大模型？准备用在什么业务上？
    * GPT-4o可以直接用谷歌上的优质、更新及时的内容做RAG，但国内的平台都越来越封闭反爬，目前可检索到的文章质量可以用Trash来形容，您觉得这个问题怎么解决？
    * 您觉得我有哪些地方需要加强学习？

### 二面（咕咕）

<ClientOnly>
  <leave/>
</ClientOnly/>