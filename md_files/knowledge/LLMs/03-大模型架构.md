---
title: 大模型架构
sidebar: true
# isShowComments: true
---
# 大模型架构

<ClientOnly>
<title-pv/>
</ClientOnly>


## Casual/Prefix Model
### Casual Model
### Prefix Model


## 注意力
### 自注意力
### MHA
### GQA
### MQA
### MLA
### 线性注意力
### 分组注意力
### 滑动窗口注意力


## 位置编码
### 绝对编码
### 相对编码


## 架构
### Encoder-only
### Decoder-only
### Encoder-Decoder


## 开源大模型

### GLM系列
#### GLM4-6B
#### GLM4-9B

### Mistral
#### Mistral-7B
滑动窗口+分组注意力
#### Mistral-8*7/22B

### Gemma-7B

### LlaMA系列
#### LlaMA-2-7B
#### LlaMA-2-13B
#### LlaMA-3-8B

### 英伟达新模型
### 苹果新模型

## 闭源大模型
### GPT系列
#### GPT-3.5
#### GPT-4
#### GPT-4o
#### GPT-4o-mini
#### o1
强化学习训练：o1模型的核心在于其采用了强化学习的方法进行训练。这种方法使模型能够在不断试错的过程中优化其决策策略，从而提升其在复杂推理任务中的表现。内部思维链生成：不同于传统的语言模型，o1在回答之前会生成一个内部的思维链。这个思路链是一个逐步推导、逐步分解问题的过程，它模拟了人类思考的方式，使得模型能够更深入地理解问题并给出更准确的答案。复杂推理能力：通过强化学习和内部思维链的生成，o1在复杂推理能力上实现了显著提升。它能够在数学、编码、科学等多个领域表现出色，解决一些传统模型难以应对的复杂问题。
### Claude3
### 文心一言
### Kimi
### 豆包
### 百川

* Instruct
* Chat
* Base


<ClientOnly>
  <leave/>
</ClientOnly/>