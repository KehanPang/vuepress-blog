---
title: 面试记录
sidebar: true
---

# 实习面试记录

<ClientOnly>
<title-pv/>
</ClientOnly>

## 百川智能LLM应用

### 一面凉经

* 自我介绍：为什么对LLM感兴趣，对LLM有多少了解？
* 项目经历：论文核心创新点，为什么LLM在这个场景下相较于Bert有优势
* Encoder-decoder、Encode-only和Decoder-only架构的区别与优势
* RAG的技术手段
* 如何对RAG检索到的文档选优？
* 模型无法有效利用RAG检索到的文件该怎么办？
* 代码手撕多头注意力？
* GCN、GAT的基本思想？
* GAT和自注意力机制的联系？

## 美团基座LLM

### 一面凉经

* 自我介绍
* 项目经历
    * 论文核心创新点
    * 用了多少数据进行训练？
    * 这些数据是怎么获取的？
    * 用的什么模型？多大的模型？为什么用这个模型？
    * 为什么不选用QWen、BaiChuan、GLM-4等大模型？
    * 抽取出的特征是手动预设的还是自动抽取的？
    * 在同一场景下需不需要进行特征对齐，也就是规定哪个位置必须是什么属性？比如第一个位置必须是名字，第二个位置必须是年龄？
    * 你的项目有没有微调大模型？为什么要微调？
    * SFT前后，特征能正确对齐吗？
    * 对于亚马逊的爬虫网页信息来说，有哪些内容是可以用来哺育大模型的？
    * 如果有1T级别的数据，怎么选取出1M级别适合大模型训练的数据？
* 目前有接触到哪些RAG的科研？
* 这些科研落地了吗？
* 了解o1吗？o1-mini和o1相较于GPT-4做了哪些改进？
* 你对o1的逻辑计算能力是怎么看待的？
* 多智能体协调会遇到什么问题？
* 智能体是怎么样调用工具的？
* LlaMA-2和LlaMA-3的差异？（训练数据差异，模型结构差异，适合任务差异）
* Mistral-7B和LlaMA-3-8B的差异？（训练数据差异，模型结构差异，适合任务差异）
* 手撕代码：K-means
* 反问环节：
    * 美团目前在做的是什么大模型？准备用在什么业务上？
    * 您对工业界大模型方向是怎么看的？
        * 这两年热度过大，以后会逐渐回归正常热度，看openai能不能探索出新的商业模式，从业者需要不断学习、精进自己的技能
    * 我有哪些地方可以改进？
        * 加强对前沿知识的深入了解、多一些实操经验，尤其是研究方向有差异的人更需要深入了解。

<ClientOnly>
  <leave/>
</ClientOnly/>